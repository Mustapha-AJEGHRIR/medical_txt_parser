{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from data_preprocessing import Get_and_process_data\n",
    "from datasets import Dataset, ClassLabel, Sequence, load_dataset, load_metric\n",
    "from transformers import (AutoModelForTokenClassification, \n",
    "                          AutoTokenizer, \n",
    "                          DataCollatorForTokenClassification,\n",
    "                          pipeline,\n",
    "                          TrainingArguments, \n",
    "                          Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"allenai/scibert_scivocab_uncased\"\n",
    "batch_size = 16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading raw text: 100%|██████████| 170/170 [00:09<00:00, 18.73it/s]\n",
      "Processing raw text: 170it [00:00, 192.46it/s]\n",
      "Adding unlabeled lines: 8454it [00:01, 4922.55it/s]\n",
      "Formatting dataset: 16525it [00:02, 7264.53it/s]\n",
      "Using custom data configuration default-468b556b8c574403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/mus5900/.cache/huggingface/datasets/json/default-468b556b8c574403/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb91fc04562474d9ac7cc6c330cce9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7233004ee664d1aab8bfb4fa320c792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/mus5900/.cache/huggingface/datasets/json/default-468b556b8c574403/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a597cc6e7f494c7ea4ace2827549916e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c443bb5aac4de78b03fc0301505a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15593 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4881a9be93143298e013cd407a580d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/821 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mus5900/.cache/huggingface/datasets/json/default-468b556b8c574403/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-5814df5346ec4747.arrow\n",
      "Loading raw text for test: 100%|██████████| 128/128 [00:09<00:00, 13.02it/s]\n",
      "Formatting test data: 13617it [00:00, 19259.50it/s]\n",
      "Using custom data configuration default-f5596ef569de00d0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/mus5900/.cache/huggingface/datasets/json/default-f5596ef569de00d0/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205bd2505bc948e490b08e001a8571c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3e1ea79efc4829b0c1cb4f4c621c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/mus5900/.cache/huggingface/datasets/json/default-f5596ef569de00d0/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41698ea2cfa4736b54c3ce6956aeab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18afbf273cd14348a6fec91c17088414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13617 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader = Get_and_process_data(tokenizer, train_split=0.95, add_unlabeled=False)\n",
    "D = data_loader.get_dataset()\n",
    "label_list = data_loader.get_label_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /home/m5u9s00/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /home/m5u9s00/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"training_logs/{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # learning_rate=1e-5,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.05,\n",
    "    logging_steps=5,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=D[\"train\"],\n",
    "    eval_dataset=D[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running training *****\n",
      "  Num examples = 15593\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9760\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9760' max='9760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9760/9760 48:00, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.600600</td>\n",
       "      <td>0.684513</td>\n",
       "      <td>0.269297</td>\n",
       "      <td>0.300191</td>\n",
       "      <td>0.283906</td>\n",
       "      <td>0.793004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.410699</td>\n",
       "      <td>0.449927</td>\n",
       "      <td>0.592734</td>\n",
       "      <td>0.511551</td>\n",
       "      <td>0.870241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.339691</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.674952</td>\n",
       "      <td>0.597798</td>\n",
       "      <td>0.894957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.277114</td>\n",
       "      <td>0.605307</td>\n",
       "      <td>0.697897</td>\n",
       "      <td>0.648313</td>\n",
       "      <td>0.912896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.295672</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.736138</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>0.913992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.326391</td>\n",
       "      <td>0.633224</td>\n",
       "      <td>0.736138</td>\n",
       "      <td>0.680813</td>\n",
       "      <td>0.914590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.326181</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.760994</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.924357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.352940</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.757170</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.922962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.378488</td>\n",
       "      <td>0.708042</td>\n",
       "      <td>0.774379</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.926251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.393227</td>\n",
       "      <td>0.684838</td>\n",
       "      <td>0.768642</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.925653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.417449</td>\n",
       "      <td>0.691379</td>\n",
       "      <td>0.766730</td>\n",
       "      <td>0.727108</td>\n",
       "      <td>0.921666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.433513</td>\n",
       "      <td>0.702238</td>\n",
       "      <td>0.780115</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.925154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.440595</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>0.772467</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.920371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.460799</td>\n",
       "      <td>0.727599</td>\n",
       "      <td>0.776291</td>\n",
       "      <td>0.751156</td>\n",
       "      <td>0.924357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.470791</td>\n",
       "      <td>0.727110</td>\n",
       "      <td>0.774379</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.921766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.483001</td>\n",
       "      <td>0.700342</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.738934</td>\n",
       "      <td>0.920470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.486230</td>\n",
       "      <td>0.731449</td>\n",
       "      <td>0.791587</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.923460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.486618</td>\n",
       "      <td>0.714536</td>\n",
       "      <td>0.780115</td>\n",
       "      <td>0.745887</td>\n",
       "      <td>0.925055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.487767</td>\n",
       "      <td>0.709059</td>\n",
       "      <td>0.778203</td>\n",
       "      <td>0.742024</td>\n",
       "      <td>0.925952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.485187</td>\n",
       "      <td>0.705373</td>\n",
       "      <td>0.778203</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.924855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-1500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-2500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-3500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-4500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-5500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-6500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-7500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-8500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9000\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9000/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9500\n",
      "Configuration saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9500/config.json\n",
      "Model weights saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in training_logs/scibert_scivocab_uncased-finetuned-ner/checkpoint-9500/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9760, training_loss=0.15571206227638168, metrics={'train_runtime': 2881.2935, 'train_samples_per_second': 108.236, 'train_steps_per_second': 3.387, 'total_flos': 8168461354174668.0, 'train_loss': 0.15571206227638168, 'epoch': 20.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 821\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='539' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ABSENT': {'precision': 0.7391304347826086,\n",
       "  'recall': 0.8225806451612904,\n",
       "  'f1': 0.7786259541984734,\n",
       "  'number': 62},\n",
       " 'CONDITIONAL': {'precision': 0.14285714285714285,\n",
       "  'recall': 0.25,\n",
       "  'f1': 0.18181818181818182,\n",
       "  'number': 4},\n",
       " 'HYPOTHETICAL': {'precision': 0.4,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.4444444444444445,\n",
       "  'number': 8},\n",
       " 'POSSIBLE': {'precision': 0.375,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1': 0.35294117647058826,\n",
       "  'number': 9},\n",
       " 'PRESENT': {'precision': 0.6534090909090909,\n",
       "  'recall': 0.7467532467532467,\n",
       "  'f1': 0.696969696969697,\n",
       "  'number': 154},\n",
       " 'TEST': {'precision': 0.7111111111111111,\n",
       "  'recall': 0.7804878048780488,\n",
       "  'f1': 0.7441860465116279,\n",
       "  'number': 123},\n",
       " 'TREATMENT': {'precision': 0.7965116279069767,\n",
       "  'recall': 0.8404907975460123,\n",
       "  'f1': 0.8179104477611939,\n",
       "  'number': 163},\n",
       " 'overall_precision': 0.7053726169844021,\n",
       " 'overall_recall': 0.7782026768642447,\n",
       " 'overall_f1': 0.7400000000000001,\n",
       " 'overall_accuracy': 0.9248554913294798}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(D[\"val\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: absent_indices_end, hypothetical_indices_start, possible, hypothetical, offset_mapping, conditional_indices_start, associated with someone else_indices_end, test, present_indices_end, present_indices_start, test_indices_start, associated with someone else, absent_indices_start, treatment_indices_start, possible_indices_end, hypothetical_indices_end, text, treatment_indices_end, associated with someone else_indices_start, conditional_indices_end, possible_indices_start, treatment, conditional, present, absent, test_indices_end.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 16414\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "predictions_2, labels_2, _ = trainer.predict(D[\"test\"])\n",
    "predictions_2 = np.argmax(predictions_2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u =  7481\n"
     ]
    }
   ],
   "source": [
    "x= 0\n",
    "u = 0\n",
    "for i in range(x, x+16000):\n",
    "    if sum(predictions_2[i])>0:\n",
    "        u+=1\n",
    "        # print(\"i = \", i, end=\"\\t -> \")\n",
    "        # print(sum(predictions_2[i]))\n",
    "print(\"u = \", u)\n",
    "\n",
    "# 7510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       0, 4, 0, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2[194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in logs/model_50_warmup_epochs/config.json\n",
      "Model weights saved in logs/model_50_warmup_epochs/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# model.save_pretrained(\"logs/model_50_warmup_epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat to the initial format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 0\n",
      "max : 14\n"
     ]
    }
   ],
   "source": [
    "prediction = np.load(\"../data/prediction.npy\")\n",
    "print(\"min :\", min(prediction.reshape(-1)))\n",
    "print(\"max :\", max(prediction.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'o',\n",
       " 1: 'test',\n",
       " 2: 'test',\n",
       " 3: 'treatment',\n",
       " 4: 'treatment',\n",
       " 5: 'present',\n",
       " 6: 'present',\n",
       " 7: 'absent',\n",
       " 8: 'absent',\n",
       " 9: 'possible',\n",
       " 10: 'possible',\n",
       " 11: 'conditional',\n",
       " 12: 'conditional',\n",
       " 13: 'hypothetical',\n",
       " 14: 'hypothetical',\n",
       " 15: 'associated with someone else',\n",
       " 16: 'associated with someone else'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list\n",
    "token_to_label = {token: token.split(\"-\")[-1] for token in label_list}\n",
    "token_id_to_label = {i: token_to_label[token].lower() for i, token in enumerate(label_list)}\n",
    "token_id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_to_concept = {\n",
    "    \"test\" : \"test\",\n",
    "    \"treatment\" : \"treatment\",\n",
    "    \"present\" : \"problem\",\n",
    "    \"absent\" : \"problem\",\n",
    "    \"possible\" : \"problem\",\n",
    "    \"conditional\" : \"problem\",\n",
    "    \"hypothetical\" : \"problem\",\n",
    "    \"associated with someone else\" : \"problem\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'row', 'filename', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'],\n",
       "    num_rows: 13617\n",
       "})"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = D[\"test\"]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'the ventricles and sulci are mildly prominent , but stable in size and appearance .', 'row': 151, 'test': [], 'test_indices_start': [], 'test_indices_end': [], 'treatment': [], 'treatment_indices_start': [], 'treatment_indices_end': [], 'present': ['mildly prominent'], 'present_indices_start': [29], 'present_indices_end': [45], 'absent': [], 'absent_indices_start': [], 'absent_indices_end': [], 'possible': [], 'possible_indices_start': [], 'possible_indices_end': [], 'conditional': [], 'conditional_indices_start': [], 'conditional_indices_end': [], 'hypothetical': [], 'hypothetical_indices_start': [], 'hypothetical_indices_end': [], 'associated with someone else': [], 'associated with someone else_indices_start': [], 'associated with someone else_indices_end': [], 'input_ids': [102, 111, 15077, 30113, 137, 9271, 1644, 220, 28964, 9295, 422, 563, 3229, 121, 1243, 137, 6540, 205, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [[0, 0], [0, 3], [4, 13], [13, 14], [15, 18], [19, 22], [22, 24], [25, 28], [29, 35], [36, 45], [46, 47], [48, 51], [52, 58], [59, 61], [62, 66], [67, 70], [71, 81], [82, 83], [0, 0]], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, -100]}\n",
      "len of labels : 19\n",
      "len of offset_mapping : 19\n",
      "len of input_ids : 19\n"
     ]
    }
   ],
   "source": [
    "for i,a in enumerate(D[\"train\"]):\n",
    "        print(a)\n",
    "        print(\"len of labels :\", len(a[\"labels\"]))\n",
    "        print(\"len of offset_mapping :\", len(a[\"offset_mapping\"]))\n",
    "        print(\"len of input_ids :\", len(a[\"input_ids\"]))\n",
    "        # print(prediction[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [213]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from utils.save_predictions import save_predictions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# save_predictions(test_data, prediction)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_data):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0006\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/arrow_dataset.py:1658\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;124;03m\"\"\"Iterate through the examples.\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m \n\u001b[1;32m   1654\u001b[0m \u001b[38;5;124;03mIf a formatting is set with :meth:`Dataset.set_format` rows will be returned with the\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;124;03mselected format.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[0;32m-> 1658\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/arrow_dataset.py:1900\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1899\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1900\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/formatting/formatting.py:529\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    527\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m table\n\u001b[1;32m    528\u001b[0m query_type \u001b[38;5;241m=\u001b[39m key_to_query_type(key)\n\u001b[0;32m--> 529\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m \u001b[43mPythonFormatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[38;5;241m=\u001b[39mquery_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/formatting/formatting.py:276\u001b[0m, in \u001b[0;36mFormatter.__init__\u001b[0;34m(self, features, decoded)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoded \u001b[38;5;241m=\u001b[39m decoded\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder \u001b[38;5;241m=\u001b[39m PythonFeaturesDecoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_features_decoder \u001b[38;5;241m=\u001b[39m \u001b[43mPandasFeaturesDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/formatting/formatting.py:230\u001b[0m, in \u001b[0;36mPandasFeaturesDecoder.__init__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPandasFeaturesDecoder\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features):\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from utils.save_predictions import save_predictions\n",
    "\n",
    "# save_predictions(test_data, prediction)\n",
    "for i,a in enumerate(test_data):\n",
    "    if sum(prediction[i])==0 or i<2022:\n",
    "        pass\n",
    "    else:\n",
    "        # print(a)\n",
    "        pred = prediction[i][:len(a['input_ids'])] #remove padding zeros\n",
    "        # print(pred)\n",
    "        \n",
    "        # -------------------------------- Real thing -------------------------------- #\n",
    "        old_token = None\n",
    "        splits = []\n",
    "        for j,token in enumerate(pred):\n",
    "            if old_token!=None and token_id_to_label[old_token] == token_id_to_label[token]: #continue same sequence\n",
    "                splits[-1][1] = j\n",
    "            else: #start a new sequence\n",
    "                if len(splits) :\n",
    "                    splits[-1][1] = j\n",
    "                old_token = token\n",
    "                splits.append([j, None, token])\n",
    "        for split in splits :\n",
    "            token = split[-1]\n",
    "            if token == 0:\n",
    "                continue\n",
    "            mapping_list = a['offset_mapping'][split[0]:split[1]]\n",
    "            mapping = [mapping_list[0][0], mapping_list[-1][1]] #by character\n",
    "            # print(a[\"text\"][mapping[0]:mapping[1]], end= \"\\t->\\t\")\n",
    "            # print(token_id_to_label[token])\n",
    "            \n",
    "            # ------------------------------- word_mapping ------------------------------- #\n",
    "            # print(\"mapping : \", mapping)\n",
    "            word_mapping_0 = len(a['text'][:mapping[0]].strip().split(\" \"))\n",
    "            word_mapping_1 = word_mapping_0 + len(a['text'][mapping[0]:mapping[1]].strip().split(\" \")) - 1\n",
    "            word_mapping = [word_mapping_0, word_mapping_1]\n",
    "            \n",
    "            # -------------------------------- file lines -------------------------------- #\n",
    "            con_line = 'c=\"'+str(a[\"text\"][mapping[0]:mapping[1]])\n",
    "            con_line += '\" ' \n",
    "            con_line += str(a[\"row\"]) + \":\" + str(word_mapping[0])\n",
    "            con_line += ' '\n",
    "            con_line += str(a[\"row\"]) + \":\" + str(word_mapping[1])\n",
    "            con_line += '||t=\"'\n",
    "            con_line += ast_to_concept[token_id_to_label[token]] + '\"'\n",
    "            # print(\"===>con_line :\", con_line)\n",
    "            if ast_to_concept[token_id_to_label[token]] == \"problem\":\n",
    "                ast_line = con_line\n",
    "                ast_line += '||a=\"'\n",
    "                ast_line += token_id_to_label[token]\n",
    "                ast_line += '\"'\n",
    "                print(ast_line)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # print(\"len of offset_mapping :\", len(a[\"offset_mapping\"]))\n",
    "        # print(\"len of input_ids :\", len(a[\"input_ids\"]))\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"doses were slowly tapered over her hospital course , and her Prograf level was adjusted to\"\n",
    "len(a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16414"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataset' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Dataset' object does not support item assignment"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d650a3b94c458c273a536969f20832049d87778dafdd87df0ff4ffcada142abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
